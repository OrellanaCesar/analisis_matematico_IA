{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ce50a8",
   "metadata": {},
   "source": [
    "## RESPUESTAS \n",
    "#### 1) Diferencias entre `QDA`y `TensorizedQDA`\n",
    "\n",
    "1. ¿Sobre qué paraleliza `TensorizedQDA`? ¿Sobre las $k$ clases, las $n$ observaciones a predecir, o ambas?\n",
    "\n",
    "Sobre las $k$ clases.\n",
    "\n",
    "2. Analizar los shapes de `tensor_inv_covs` y `tensor_means` y explicar paso a paso cómo es que `TensorizedQDA` llega a predecir lo mismo que `QDA`.\n",
    "\n",
    "`tensor_inv_covs` es un array de NumPy de $\\mathbb{R}^{k \\times p \\times n}$\n",
    "\n",
    "`tensor_means` es un array de NumPy de $\\mathbb{R}^{k \\times p \\times 1}$\n",
    "\n",
    "QDA en el método `_predict_one` itera sobre las $k$ clases calculando el logaritmo de la probabilidad a posteriori para cada una, usando el método `_predict_log_conditional` (este método devuelve un escalar), obteniendo una lista (de tamaño $k$) con la probabilidad de que la observación pertenezca a cada una de las clases. Luego, devuelve el argumento de la mayor probabilidad en dicha lista.\n",
    "\n",
    "inv_cov $\\in \\mathbb{R}^{p \\times p}$\n",
    "\n",
    "means, ubiased_x $\\in \\mathbb{R}^{p \\times 1}$\n",
    "\n",
    "unbiased_x.T @ inv_cov @ unbiased_x $\\rarr$ $(1 \\times p) @ (p \\times p) @ (p \\times 1) $ $\\in \\mathbb{R}^{1 \\times 1} \\rarr $ escalar\n",
    "\n",
    "Entonces, `_predict_log_conditional` devuelve un escalar.\n",
    "\n",
    "TensorizedQDA directamente hace el cálculo de los logaritmos de las probabilidades a posteriori de forma matricial en el método `_predict_log_conditionals`, el cual directamente devuelve un vector columna $\\mathbb{R}^{p \\times 1}$, similar a la lista obtenida con el bucle for dentro del método `_predict_one` de la clase `QDA`. Luego, el método `_predict_one` para esta clase solo se encarga de encotrar el argumento que maximiza la probailidad (logarítmica).\n",
    "\n",
    "tensor_inv_cov # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7653d5",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71311f41",
   "metadata": {},
   "source": [
    "### 2) Optimización\n",
    "\n",
    "Debido a la forma cuadrática de QDA, no se puede predecir para $n$ observaciones en una sola pasada (utilizar $X \\in \\mathbb{R}^{p \\times n}$ en vez de $x \\in \\mathbb{R}^p$) sin pasar por una matriz de $n \\times n$ en donde se computan todas las interacciones entre observaciones. Se puede acceder al resultado recuperando sólo la diagonal de dicha matriz, pero resulta ineficiente en tiempo y (especialmente) en memoria. Aún así, es *posible* que el modelo funcione más rápido.\n",
    "\n",
    "3. Implementar el modelo `FasterQDA` (se recomienda heredarlo de `TensorizedQDA`) de manera de eliminar el ciclo for en el método predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b246eaf3",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "Poder eliminar el ciclo for de predict. Es decir, predecir las n observaciones y k clases en un mismo paso. \n",
    "\n",
    "En BaseBayesianClassifier\n",
    "\n",
    "predict(self, X) → tiene ciclo for recorre las n observaciones, y llama a predict_one, donde TensorizedQDA ya paraleliza las k clases. \n",
    "\n",
    "-------------\n",
    "def predict(self, X): → llama a predict_one por cada observación\n",
    "\n",
    "def _predict_one(self, x): → llama a _predict_log_conditional para hacer el argmax de la suma\n",
    "\n",
    "$$\n",
    "\\log\\hat{f}_j(x) + \\log\\hat{\\pi}_j\n",
    "$$\n",
    "\n",
    "def _predict_log_conditional(self, x, class_idx)\n",
    "$$\n",
    "\\log{f_j(x)} = -\\frac{1}{2}\\log |\\Sigma_j| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j) + C\n",
    "$$\n",
    "----------------\n",
    "\n",
    "Buscamos calcular la forma cuadrática para muchas observaciones a la vez:\n",
    "\n",
    "$$(x-\\mu_j)^T \\Sigma^{-1} (x- \\mu_j)$$\n",
    "\n",
    "Donde usamos : _predict_log_conditional(x, class_idx)\n",
    "\n",
    "unbiased_x = x - mean_j\n",
    "\n",
    "unbiased_x.T @ inv_cov_j @ unbiased_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef0bc62",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2e0f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy        as np\n",
    "import pandas       as pd\n",
    "import numpy.linalg as LA\n",
    "from scipy.linalg           import cholesky, solve_triangular\n",
    "from scipy.linalg.lapack    import dtrtri\n",
    "\n",
    "from base.qda               import QDA, TensorizedQDA\n",
    "from base.cholesky          import QDA_Chol1, QDA_Chol2, QDA_Chol3\n",
    "from utils.bench            import Benchmark\n",
    "from utils.datasets         import (get_letters_dataset,label_encode)                                                     \n",
    "from numpy.random           import RandomState"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14291914",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50995c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benching params:\n",
      "Total runs: 150\n",
      "Warmup runs: 20\n",
      "Peak Memory usage runs: 30\n",
      "Running time runs: 100\n",
      "Train size rows (approx): 16000\n",
      "Test size rows (approx): 4000\n",
      "Test size fraction: 0.2\n"
     ]
    }
   ],
   "source": [
    "# dataset de letters\n",
    "X_letter, y_letter = get_letters_dataset()\n",
    "\n",
    "# encoding de labels\n",
    "y_letter_encoded = label_encode(y_letter.reshape(-1,1)) # hago reshape para que quede como matriz columna\n",
    "\n",
    "# instanciacion del benchmark\n",
    "b = Benchmark(\n",
    "    X_letter, y_letter_encoded,\n",
    "    same_splits=False,\n",
    "    n_runs=100,\n",
    "    warmup=20,\n",
    "    mem_runs=30,\n",
    "    test_sz=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810f7778",
   "metadata": {},
   "source": [
    "### Prueba QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "735a04a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  5, 18,  7,  7]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda = QDA()\n",
    "\n",
    "qda.fit(X_letter.T, y_letter_encoded)\n",
    "\n",
    "qda.predict(X_letter.T[:, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f24cec0",
   "metadata": {},
   "source": [
    "### Prueba TensorizedQDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b54275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  5, 18,  7,  7]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqda = TensorizedQDA()\n",
    "\n",
    "tqda.fit(X_letter.T, y_letter_encoded)\n",
    "\n",
    "tqda.predict(X_letter.T[:, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634477c4",
   "metadata": {},
   "source": [
    "### FasterQDA\n",
    "\n",
    "Definir una clase FasterQDA que herede de TensorizedQDA y redefina predict para predecir todas las observaciones juntas, sin el for sobre filas de X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b21da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FasterQDA(TensorizedQDA):\n",
    "    \"\"\"\n",
    "    Versión vectorizada (sin bucles en predict), \n",
    "    con matriz intermedia ineficiente (matriz N x N).\n",
    "    \"\"\"\n",
    "\n",
    "    def _predict_log_conditionals_batch(self, X):\n",
    "        # Dimensiones iniciales\n",
    "        k, p, _ = self.tensor_means.shape # self.tensor_means: (k, p, 1)    → k clases, p features\n",
    "        n = X.shape[1]                    # X: (p, n)                       → p features, n observaciones\n",
    "\n",
    "        # Cálculo resta: D = X - medias\n",
    "        D = X[None, :, :] - self.tensor_means   # X: (1, p, n) - Medias: (k, p, 1) → D: (k, p, n)\n",
    "\n",
    "        # Cálculo de la distancia cuadrática \n",
    "        quad_terms = np.empty((k, n)) # Almacena distancias por cada k clase y observación n\n",
    "\n",
    "        for j in range(k):\n",
    "            D_j = D[j]                          # Shape: (p, n)\n",
    "            inv_cov_j = self.tensor_inv_cov[j]  # Shape: (p, p)\n",
    "\n",
    "            # ---------------------------------------------------------\n",
    "            # Generación de matriz n x n\n",
    "            # ---------------------------------------------------------\n",
    "            # Al multiplicar D_j.T (n, p) @ inv (p, p) @ D_j (p, n), el resultado final es una matriz de (n, n)\n",
    "            # solo nos importa cada dato consigo mismo (la diagonal)\n",
    "            \n",
    "            Q_j = D_j.T @ inv_cov_j @ D_j      # matriz (n, n)\n",
    "\n",
    "            # Nos quedamos con la diagonal \n",
    "            quad_terms[j, :] = np.diag(Q_j)    \n",
    "            # ---------------------------------------------------------\n",
    "\n",
    "        \n",
    "        # log_det es (k,). Lo convertimos a (k, 1) para operar con quad_terms\n",
    "        log_det = np.log(LA.det(self.tensor_inv_cov))[:, None]\n",
    "        \n",
    "        # Fórmula final: 0.5 * log_det - 0.5 * distancia\n",
    "        return 0.5 * log_det - 0.5 * quad_terms\n",
    "\n",
    "    def predict(self, X):\n",
    "        # traigo el log-condicionales \n",
    "        log_cond = self._predict_log_conditionals_batch(X)\n",
    "\n",
    "        # Sumamos el log_a_priori \n",
    "        log_post = self.log_a_priori[:, None] + log_cond\n",
    "\n",
    "        # Elegimos la clase ganadora → por columna\n",
    "        y_hat = np.argmax(log_post, axis=0)\n",
    "\n",
    "        return y_hat.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553097f6",
   "metadata": {},
   "source": [
    "## Comparar modelos con benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfa2cf8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb814b545cff4f7aac4ce6b62d7525f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA (MEM):   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67da30fbe2f3409684b9e7e42e42e238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA (TIME):   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d985c912ba02401ca38900b9b1ac0c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TensorizedQDA (MEM):   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090913e82d9b48149dda106b92725024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TensorizedQDA (TIME):   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956171b940ea4d689aaf54324f9a8ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FasterQDA (MEM):   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9056d48b23bf4ba1af01371708285ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FasterQDA (TIME):   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QDA \n",
    "b.bench(QDA)\n",
    "\n",
    "# TensorizedQDA\n",
    "b.bench(TensorizedQDA)\n",
    "\n",
    "# FasterQDA\n",
    "b.bench(FasterQDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "119f3fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_median_ms</th>\n",
       "      <th>train_std_ms</th>\n",
       "      <th>test_median_ms</th>\n",
       "      <th>test_std_ms</th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>train_mem_median_mb</th>\n",
       "      <th>train_mem_std_mb</th>\n",
       "      <th>test_mem_median_mb</th>\n",
       "      <th>test_mem_std_mb</th>\n",
       "      <th>train_speedup</th>\n",
       "      <th>test_speedup</th>\n",
       "      <th>train_mem_reduction</th>\n",
       "      <th>test_mem_reduction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>11.25435</td>\n",
       "      <td>1.488169</td>\n",
       "      <td>2274.83455</td>\n",
       "      <td>36.400248</td>\n",
       "      <td>0.886117</td>\n",
       "      <td>0.270081</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.099136</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TensorizedQDA</th>\n",
       "      <td>10.67465</td>\n",
       "      <td>3.035770</td>\n",
       "      <td>393.82020</td>\n",
       "      <td>12.726946</td>\n",
       "      <td>0.885303</td>\n",
       "      <td>0.268448</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.154083</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>1.054306</td>\n",
       "      <td>5.776328</td>\n",
       "      <td>1.006082</td>\n",
       "      <td>0.643395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FasterQDA</th>\n",
       "      <td>8.95225</td>\n",
       "      <td>3.968961</td>\n",
       "      <td>1171.69815</td>\n",
       "      <td>202033.336026</td>\n",
       "      <td>0.884827</td>\n",
       "      <td>0.268936</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>258.234657</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>1.257153</td>\n",
       "      <td>1.941485</td>\n",
       "      <td>1.004255</td>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train_median_ms  train_std_ms  test_median_ms    test_std_ms  \\\n",
       "model                                                                         \n",
       "QDA                   11.25435      1.488169      2274.83455      36.400248   \n",
       "TensorizedQDA         10.67465      3.035770       393.82020      12.726946   \n",
       "FasterQDA              8.95225      3.968961      1171.69815  202033.336026   \n",
       "\n",
       "               mean_accuracy  train_mem_median_mb  train_mem_std_mb  \\\n",
       "model                                                                 \n",
       "QDA                 0.886117             0.270081          0.002008   \n",
       "TensorizedQDA       0.885303             0.268448          0.002145   \n",
       "FasterQDA           0.884827             0.268936          0.001919   \n",
       "\n",
       "               test_mem_median_mb  test_mem_std_mb  train_speedup  \\\n",
       "model                                                               \n",
       "QDA                      0.099136         0.001261       1.000000   \n",
       "TensorizedQDA            0.154083         0.000118       1.054306   \n",
       "FasterQDA              258.234657         0.000375       1.257153   \n",
       "\n",
       "               test_speedup  train_mem_reduction  test_mem_reduction  \n",
       "model                                                                 \n",
       "QDA                1.000000             1.000000            1.000000  \n",
       "TensorizedQDA      5.776328             1.006082            0.643395  \n",
       "FasterQDA          1.941485             1.004255            0.000384  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = b.summary(baseline=\"QDA\")\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de007667",
   "metadata": {},
   "source": [
    "Vemos que TensorizedQDA entrena en el mismo tiempo que el QDA base y clasifica con la misma accuracy, pero es mucho más rápido en predicción.\n",
    "FasterQDA no lo mejora porque empieza a comparar todas las observaciones contra todas y arma una matriz gigante N×N que consume 258 MB de RAM y ralentiza todo el proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2c8795",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa4cbe4",
   "metadata": {},
   "source": [
    "## Cholesky\n",
    "\n",
    "Hasta ahora todos los esfuerzos fueron enfocados en realizar una predicción más rápida. Los tiempos de entrenamiento (teóricos al menos) siguen siendo los mismos o hasta (minúsculamente) peores, dado que todas las mejoras siguen llamando al método `_fit_params` original de `QDA`.\n",
    "\n",
    "La descomposición/factorización de [Cholesky](https://en.wikipedia.org/wiki/Cholesky_decomposition#Statement) permite factorizar una matriz definida positiva $A = LL^T$ donde $L$ es una matriz triangular inferior. En particular, si bien se asume que $p \\ll n$, invertir la matriz de covarianzas $\\Sigma$ para cada clase impone un cuello de botella que podría alivianarse. Teniendo en cuenta que las matrices de covarianza son simétricas y salvo degeneración, definidas positivas, Cholesky como mínimo debería permitir invertir la matriz más rápido.\n",
    "\n",
    "*Nota: observar que calcular* $A^{-1}b$ *equivale a resolver el sistema* $Ax=b$.\n",
    "\n",
    "### 3) Diferencias entre implementaciones de `QDA_Chol`\n",
    "\n",
    "8. Si una matriz $A$ tiene fact. de Cholesky $A=LL^T$, expresar $A^{-1}$ en términos de $L$. ¿Cómo podría esto ser útil en la forma cuadrática de QDA?\n",
    "\n",
    "Al aplicar la factorización de Cholesky a la matriz de convarianzas (matriz simétrica y definida positiva siempre que no hayan features perfectaemente colineales) se puede representar como $\\Sigma = $LL^T$, de tal manera que la expresión $(x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j)$ se puede reescribir como:\n",
    "\n",
    "$$\n",
    "(x-\\mu_j)^T (L_j L_j^T)^{-1} (x- \\mu_j)\n",
    "$$\n",
    "y operando un poco:\n",
    "$$\n",
    "(x-\\mu_j)^T (L_j^{-1})^T L_j^{-1} (x- \\mu_j)\n",
    "$$\n",
    "$$\n",
    "[L_j^{-1} (x- \\mu_j)]^T [L_j^{-1} (x- \\mu_j)]\n",
    "$$\n",
    "Si representamos $L_j^{-1} (x- \\mu_j)$ como $y$, la expresión puede verse como\n",
    "$$\n",
    "y^Ty = ||y||^2\n",
    "$$\n",
    "donde $y$ puede calcularse resolviendo un sistema de ecuaciones lineales triangular, que es relativamente sencillo con sustitución hacia adelante:\n",
    "$$\n",
    "L_j y = x- \\mu_j\n",
    "$$\n",
    "Por otro lado, respecto al logaritmo del determinante la matriz de covarianzas, se puede operar de la siguiente manera:\n",
    "$$\n",
    "\\log |\\Sigma_j| = \\log |L_j L_j^T| = \\log |L_j| + \\log |L_j^T| = 2 \\log |L_j|\n",
    "$$\n",
    "donde $|L_j|$, al ser $L_j$ una matriz triangular inferior, es el producto de sus elementos en la diagonal.\n",
    "\n",
    "Finalmente, la forma cuadrática de QDA se puede reescribir como:\n",
    "$$\n",
    "\\log{f_j(x)} = \\log{ \\left( \\prod_{i=1}^p l_{ii} \\right)} - \\frac{1}{2} \\|y\\|^2\n",
    "$$\n",
    "En resumen, aplicar Cholesky en QDA transforma un problema con  inversión de matrices en un problema de resolución de sistemas de ecuaciones lineales triangulares.\n",
    "\n",
    "\n",
    "7. Explicar las diferencias entre `QDA_Chol1`y `QDA` y cómo `QDA_Chol1` llega, paso a paso, hasta las predicciones.\n",
    "\n",
    "`QDA` en su método `_fit_params` calcula e invierte la matriz de covarianzas para cada clase y las almacena en `self.inv_covs`.\n",
    "\n",
    "`QDA_Chol1`, en el mismo método, calcula la matriz de covarianzas y le aplica la factorización de Cholesky, obteniendo la matriz $L$. Luego, calcula la inversa de $L$ y la almacena en `self.L_invs`. Esto es para cada clase.\n",
    "\n",
    "A la hora de realizar una predición, en el método `_predict_log_conditional`, en `QDA` prácticamente utiliza la formulación provista inicialmente para el cálculo de la log-verosimilitud, con algunos cambios.\n",
    "$$\n",
    "\\log{f_j(x)} = \\frac{1}{2}\\log |\\Sigma_j^{-1}| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j)\n",
    "$$\n",
    ", mientras que `QDA_Chol1` aprovecha, por un lado, la propiedad de que el determinante de $L^{-1}$ es el producto de los elementos de su diagonal y, por otro, la equivalencia $$(x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j) = \\|y\\|^2$$, tal que el cálculo de la log-verosimilitud resulta:\n",
    "$$\n",
    "\\log{f_j(x)} = -\\log{ \\left( \\prod_{i=1}^p l_{ii} \\right)} - \\frac{1}{2} \\|y\\|^2\n",
    "$$\n",
    "llegando ambos al mismo resultado porque todos los reemplazos corresponden a equivalencias matemáticas, sin utilizar aproximaciones.\n",
    "\n",
    "8. ¿Cuáles son las diferencias entre `QDA_Chol1`, `QDA_Chol2` y `QDA_Chol3`?\n",
    "\n",
    "`QDA_Chol1` y `QDA_Chol2` se diferencian en que la primera calcula la inversa de $L$ y luego, para predecir, utiliza el producto de esta matriz con $x$ insesgado para calcular $y$, mientras que la segunda se queda directamente con $L$ y, para predecir, resuelve el SEL triangular para obtener $y$.\n",
    "\n",
    "`QDA_Chol3` es similar a `QDA_Chol1`, pero utiliza otra función para calcular $L^{-1}$: `QDA_Chol1` utiliza `numpy.inv()` y `QDA_Chol3` utiliza `scipy.linalg.lapack.dtrtri()`.\n",
    "\n",
    "9. Comparar la performance de las 7 variantes de QDA implementadas hasta ahora ¿Qué se observa?¿Hay alguna de las implementaciones de `QDA_Chol` que sea claramente mejor que las demás?¿Alguna que sea peor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84678165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52d47f2b0e74e13a8ab6a35e8298c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol1 (MEM):   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb320750a8c419f8c31249fce940cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol1 (TIME):   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3994b6a0ecde40218bc491bc3cc3d4e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol2 (MEM):   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1b85f1f6644e0b82e004802cdb8d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol2 (TIME):   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dee66647a7743d5a9fe1cf5edcfafca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol3 (MEM):   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2055353b6f4aab9e47ab7660dcb38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol3 (TIME):   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b.bench(QDA_Chol1)\n",
    "\n",
    "b.bench(QDA_Chol2)\n",
    "\n",
    "b.bench(QDA_Chol3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85463880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_median_ms</th>\n",
       "      <th>train_std_ms</th>\n",
       "      <th>test_median_ms</th>\n",
       "      <th>test_std_ms</th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>train_mem_median_mb</th>\n",
       "      <th>train_mem_std_mb</th>\n",
       "      <th>test_mem_median_mb</th>\n",
       "      <th>test_mem_std_mb</th>\n",
       "      <th>train_speedup</th>\n",
       "      <th>test_speedup</th>\n",
       "      <th>train_mem_reduction</th>\n",
       "      <th>test_mem_reduction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>11.25435</td>\n",
       "      <td>1.488169</td>\n",
       "      <td>2274.83455</td>\n",
       "      <td>36.400248</td>\n",
       "      <td>0.886117</td>\n",
       "      <td>0.270081</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.099136</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TensorizedQDA</th>\n",
       "      <td>10.67465</td>\n",
       "      <td>3.035770</td>\n",
       "      <td>393.82020</td>\n",
       "      <td>12.726946</td>\n",
       "      <td>0.885303</td>\n",
       "      <td>0.268448</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.154083</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>1.054306</td>\n",
       "      <td>5.776328</td>\n",
       "      <td>1.006082</td>\n",
       "      <td>0.643395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FasterQDA</th>\n",
       "      <td>8.95225</td>\n",
       "      <td>3.968961</td>\n",
       "      <td>1171.69815</td>\n",
       "      <td>202033.336026</td>\n",
       "      <td>0.884827</td>\n",
       "      <td>0.268936</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>258.234657</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>1.257153</td>\n",
       "      <td>1.941485</td>\n",
       "      <td>1.004255</td>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol1</th>\n",
       "      <td>9.67640</td>\n",
       "      <td>1.543642</td>\n",
       "      <td>1294.52870</td>\n",
       "      <td>32.113891</td>\n",
       "      <td>0.884890</td>\n",
       "      <td>0.269646</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.094719</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>1.163072</td>\n",
       "      <td>1.757269</td>\n",
       "      <td>1.001613</td>\n",
       "      <td>1.046637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol2</th>\n",
       "      <td>11.17315</td>\n",
       "      <td>5.043097</td>\n",
       "      <td>3222.76780</td>\n",
       "      <td>63.504693</td>\n",
       "      <td>0.884770</td>\n",
       "      <td>0.268478</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.095949</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>1.007267</td>\n",
       "      <td>0.705864</td>\n",
       "      <td>1.005968</td>\n",
       "      <td>1.033217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol3</th>\n",
       "      <td>10.97210</td>\n",
       "      <td>4.753426</td>\n",
       "      <td>1270.72510</td>\n",
       "      <td>28.539720</td>\n",
       "      <td>0.885433</td>\n",
       "      <td>0.268906</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.095177</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>1.025724</td>\n",
       "      <td>1.790186</td>\n",
       "      <td>1.004369</td>\n",
       "      <td>1.041603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train_median_ms  train_std_ms  test_median_ms    test_std_ms  \\\n",
       "model                                                                         \n",
       "QDA                   11.25435      1.488169      2274.83455      36.400248   \n",
       "TensorizedQDA         10.67465      3.035770       393.82020      12.726946   \n",
       "FasterQDA              8.95225      3.968961      1171.69815  202033.336026   \n",
       "QDA_Chol1              9.67640      1.543642      1294.52870      32.113891   \n",
       "QDA_Chol2             11.17315      5.043097      3222.76780      63.504693   \n",
       "QDA_Chol3             10.97210      4.753426      1270.72510      28.539720   \n",
       "\n",
       "               mean_accuracy  train_mem_median_mb  train_mem_std_mb  \\\n",
       "model                                                                 \n",
       "QDA                 0.886117             0.270081          0.002008   \n",
       "TensorizedQDA       0.885303             0.268448          0.002145   \n",
       "FasterQDA           0.884827             0.268936          0.001919   \n",
       "QDA_Chol1           0.884890             0.269646          0.002164   \n",
       "QDA_Chol2           0.884770             0.268478          0.002137   \n",
       "QDA_Chol3           0.885433             0.268906          0.001967   \n",
       "\n",
       "               test_mem_median_mb  test_mem_std_mb  train_speedup  \\\n",
       "model                                                               \n",
       "QDA                      0.099136         0.001261       1.000000   \n",
       "TensorizedQDA            0.154083         0.000118       1.054306   \n",
       "FasterQDA              258.234657         0.000375       1.257153   \n",
       "QDA_Chol1                0.094719         0.000547       1.163072   \n",
       "QDA_Chol2                0.095949         0.000366       1.007267   \n",
       "QDA_Chol3                0.095177         0.000448       1.025724   \n",
       "\n",
       "               test_speedup  train_mem_reduction  test_mem_reduction  \n",
       "model                                                                 \n",
       "QDA                1.000000             1.000000            1.000000  \n",
       "TensorizedQDA      5.776328             1.006082            0.643395  \n",
       "FasterQDA          1.941485             1.004255            0.000384  \n",
       "QDA_Chol1          1.757269             1.001613            1.046637  \n",
       "QDA_Chol2          0.705864             1.005968            1.033217  \n",
       "QDA_Chol3          1.790186             1.004369            1.041603  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = b.summary(baseline=\"QDA\")\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9633f5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_median_ms</th>\n",
       "      <th>train_std_ms</th>\n",
       "      <th>test_median_ms</th>\n",
       "      <th>test_std_ms</th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>train_mem_median_mb</th>\n",
       "      <th>train_mem_std_mb</th>\n",
       "      <th>test_mem_median_mb</th>\n",
       "      <th>test_mem_std_mb</th>\n",
       "      <th>train_speedup</th>\n",
       "      <th>test_speedup</th>\n",
       "      <th>train_mem_reduction</th>\n",
       "      <th>test_mem_reduction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>11.25435</td>\n",
       "      <td>1.488169</td>\n",
       "      <td>2274.83455</td>\n",
       "      <td>36.400248</td>\n",
       "      <td>0.886117</td>\n",
       "      <td>0.270081</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.099136</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.859792</td>\n",
       "      <td>0.569065</td>\n",
       "      <td>0.998390</td>\n",
       "      <td>0.955441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TensorizedQDA</th>\n",
       "      <td>10.67465</td>\n",
       "      <td>3.035770</td>\n",
       "      <td>393.82020</td>\n",
       "      <td>12.726946</td>\n",
       "      <td>0.885303</td>\n",
       "      <td>0.268448</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.154083</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.906484</td>\n",
       "      <td>3.287106</td>\n",
       "      <td>1.004462</td>\n",
       "      <td>0.614726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FasterQDA</th>\n",
       "      <td>8.95225</td>\n",
       "      <td>3.968961</td>\n",
       "      <td>1171.69815</td>\n",
       "      <td>202033.336026</td>\n",
       "      <td>0.884827</td>\n",
       "      <td>0.268936</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>258.234657</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>1.080890</td>\n",
       "      <td>1.104831</td>\n",
       "      <td>1.002638</td>\n",
       "      <td>0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol1</th>\n",
       "      <td>9.67640</td>\n",
       "      <td>1.543642</td>\n",
       "      <td>1294.52870</td>\n",
       "      <td>32.113891</td>\n",
       "      <td>0.884890</td>\n",
       "      <td>0.269646</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.094719</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol2</th>\n",
       "      <td>11.17315</td>\n",
       "      <td>5.043097</td>\n",
       "      <td>3222.76780</td>\n",
       "      <td>63.504693</td>\n",
       "      <td>0.884770</td>\n",
       "      <td>0.268478</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.095949</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.866040</td>\n",
       "      <td>0.401682</td>\n",
       "      <td>1.004348</td>\n",
       "      <td>0.987178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol3</th>\n",
       "      <td>10.97210</td>\n",
       "      <td>4.753426</td>\n",
       "      <td>1270.72510</td>\n",
       "      <td>28.539720</td>\n",
       "      <td>0.885433</td>\n",
       "      <td>0.268906</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.095177</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.881910</td>\n",
       "      <td>1.018732</td>\n",
       "      <td>1.002752</td>\n",
       "      <td>0.995190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train_median_ms  train_std_ms  test_median_ms    test_std_ms  \\\n",
       "model                                                                         \n",
       "QDA                   11.25435      1.488169      2274.83455      36.400248   \n",
       "TensorizedQDA         10.67465      3.035770       393.82020      12.726946   \n",
       "FasterQDA              8.95225      3.968961      1171.69815  202033.336026   \n",
       "QDA_Chol1              9.67640      1.543642      1294.52870      32.113891   \n",
       "QDA_Chol2             11.17315      5.043097      3222.76780      63.504693   \n",
       "QDA_Chol3             10.97210      4.753426      1270.72510      28.539720   \n",
       "\n",
       "               mean_accuracy  train_mem_median_mb  train_mem_std_mb  \\\n",
       "model                                                                 \n",
       "QDA                 0.886117             0.270081          0.002008   \n",
       "TensorizedQDA       0.885303             0.268448          0.002145   \n",
       "FasterQDA           0.884827             0.268936          0.001919   \n",
       "QDA_Chol1           0.884890             0.269646          0.002164   \n",
       "QDA_Chol2           0.884770             0.268478          0.002137   \n",
       "QDA_Chol3           0.885433             0.268906          0.001967   \n",
       "\n",
       "               test_mem_median_mb  test_mem_std_mb  train_speedup  \\\n",
       "model                                                               \n",
       "QDA                      0.099136         0.001261       0.859792   \n",
       "TensorizedQDA            0.154083         0.000118       0.906484   \n",
       "FasterQDA              258.234657         0.000375       1.080890   \n",
       "QDA_Chol1                0.094719         0.000547       1.000000   \n",
       "QDA_Chol2                0.095949         0.000366       0.866040   \n",
       "QDA_Chol3                0.095177         0.000448       0.881910   \n",
       "\n",
       "               test_speedup  train_mem_reduction  test_mem_reduction  \n",
       "model                                                                 \n",
       "QDA                0.569065             0.998390            0.955441  \n",
       "TensorizedQDA      3.287106             1.004462            0.614726  \n",
       "FasterQDA          1.104831             1.002638            0.000367  \n",
       "QDA_Chol1          1.000000             1.000000            1.000000  \n",
       "QDA_Chol2          0.401682             1.004348            0.987178  \n",
       "QDA_Chol3          1.018732             1.002752            0.995190  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = b.summary(baseline=\"QDA_Chol1\")\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe92679",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
