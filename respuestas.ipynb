{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ce50a8",
   "metadata": {},
   "source": [
    "## RESPUESTAS \n",
    "#### 1) Diferencias entre `QDA`y `TensorizedQDA`\n",
    "\n",
    "1. ¿Sobre qué paraleliza `TensorizedQDA`? ¿Sobre las $k$ clases, las $n$ observaciones a predecir, o ambas?\n",
    "\n",
    "Sobre las $k$ clases.\n",
    "\n",
    "2. Analizar los shapes de `tensor_inv_covs` y `tensor_means` y explicar paso a paso cómo es que `TensorizedQDA` llega a predecir lo mismo que `QDA`.\n",
    "\n",
    "`tensor_inv_covs` es un array de NumPy de $\\mathbb{R}^{k \\times p \\times n}$\n",
    "\n",
    "`tensor_means` es un array de NumPy de $\\mathbb{R}^{k \\times p \\times 1}$\n",
    "\n",
    "QDA en el método `_predict_one` itera sobre las $k$ clases calculando el logaritmo de la probabilidad a posteriori para cada una, usando el método `_predict_log_conditional` (este método devuelve un escalar), obteniendo una lista (de tamaño $k$) con la probabilidad de que la observación pertenezca a cada una de las clases. Luego, devuelve el argumento de la mayor probabilidad en dicha lista.\n",
    "\n",
    "inv_cov $\\in \\mathbb{R}^{p \\times p}$\n",
    "\n",
    "means, ubiased_x $\\in \\mathbb{R}^{p \\times 1}$\n",
    "\n",
    "unbiased_x.T @ inv_cov @ unbiased_x $\\rarr$ $(1 \\times p) @ (p \\times p) @ (p \\times 1) $ $\\in \\mathbb{R}^{1 \\times 1} \\rarr $ escalar\n",
    "\n",
    "Entonces, `_predict_log_conditional` devuelve un escalar.\n",
    "\n",
    "TensorizedQDA directamente hace el cálculo de los logaritmos de las probabilidades a posteriori de forma matricial en el método `_predict_log_conditionals`, el cual directamente devuelve un vector columna $\\mathbb{R}^{p \\times 1}$, similar a la lista obtenida con el bucle for dentro del método `_predict_one` de la clase `QDA`. Luego, el método `_predict_one` para esta clase solo se encarga de encotrar el argumento que maximiza la probailidad (logarítmica).\n",
    "\n",
    "tensor_inv_cov # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7653d5",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71311f41",
   "metadata": {},
   "source": [
    "### 2) Optimización\n",
    "\n",
    "Debido a la forma cuadrática de QDA, no se puede predecir para $n$ observaciones en una sola pasada (utilizar $X \\in \\mathbb{R}^{p \\times n}$ en vez de $x \\in \\mathbb{R}^p$) sin pasar por una matriz de $n \\times n$ en donde se computan todas las interacciones entre observaciones. Se puede acceder al resultado recuperando sólo la diagonal de dicha matriz, pero resulta ineficiente en tiempo y (especialmente) en memoria. Aún así, es *posible* que el modelo funcione más rápido.\n",
    "\n",
    "3. Implementar el modelo `FasterQDA` (se recomienda heredarlo de `TensorizedQDA`) de manera de eliminar el ciclo for en el método predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b246eaf3",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "Poder eliminar el ciclo for de predict. Es decir, predecir las n observaciones y k clases en un mismo paso. \n",
    "\n",
    "En BaseBayesianClassifier\n",
    "\n",
    "predict(self, X) → tiene ciclo for recorre las n observaciones, y llama a predict_one, donde TensorizedQDA ya paraleliza las k clases. \n",
    "\n",
    "-------------\n",
    "def predict(self, X): → llama a predict_one por cada observación\n",
    "\n",
    "def _predict_one(self, x): → llama a _predict_log_conditional para hacer el argmax de la suma\n",
    "\n",
    "$$\n",
    "\\log\\hat{f}_j(x) + \\log\\hat{\\pi}_j\n",
    "$$\n",
    "\n",
    "def _predict_log_conditional(self, x, class_idx)\n",
    "$$\n",
    "\\log{f_j(x)} = -\\frac{1}{2}\\log |\\Sigma_j| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j) + C\n",
    "$$\n",
    "----------------\n",
    "\n",
    "Buscamos calcular la forma cuadrática para muchas observaciones a la vez:\n",
    "\n",
    "$$(x-\\mu_j)^T \\Sigma^{-1} (x- \\mu_j)$$\n",
    "\n",
    "Donde usamos : _predict_log_conditional(x, class_idx)\n",
    "\n",
    "unbiased_x = x - mean_j\n",
    "\n",
    "unbiased_x.T @ inv_cov_j @ unbiased_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef0bc62",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2e0f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy        as np\n",
    "import pandas       as pd\n",
    "import numpy.linalg as LA\n",
    "from scipy.linalg           import cholesky, solve_triangular\n",
    "from scipy.linalg.lapack    import dtrtri\n",
    "\n",
    "from base.qda               import QDA, TensorizedQDA\n",
    "from base.cholesky          import QDA_Chol1, QDA_Chol2, QDA_Chol3\n",
    "from utils.bench            import Benchmark\n",
    "from utils.datasets         import (get_letters_dataset,label_encode)                                                     \n",
    "from numpy.random           import RandomState"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14291914",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50995c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benching params:\n",
      "Total runs: 150\n",
      "Warmup runs: 20\n",
      "Peak Memory usage runs: 30\n",
      "Running time runs: 100\n",
      "Train size rows (approx): 16000\n",
      "Test size rows (approx): 4000\n",
      "Test size fraction: 0.2\n"
     ]
    }
   ],
   "source": [
    "# dataset de letters\n",
    "X_letter, y_letter = get_letters_dataset()\n",
    "\n",
    "# encoding de labels\n",
    "y_letter_encoded = label_encode(y_letter.reshape(-1,1)) # hago reshape para que quede como matriz columna\n",
    "\n",
    "# instanciacion del benchmark\n",
    "b = Benchmark(\n",
    "    X_letter, y_letter_encoded,\n",
    "    same_splits=False,\n",
    "    n_runs=100,\n",
    "    warmup=20,\n",
    "    mem_runs=30,\n",
    "    test_sz=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810f7778",
   "metadata": {},
   "source": [
    "### Prueba QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "735a04a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  5, 18,  7,  7]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda = QDA()\n",
    "\n",
    "qda.fit(X_letter.T, y_letter_encoded)\n",
    "\n",
    "qda.predict(X_letter.T[:, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f24cec0",
   "metadata": {},
   "source": [
    "### Prueba TensorizedQDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b54275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  5, 18,  7,  7]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqda = TensorizedQDA()\n",
    "\n",
    "tqda.fit(X_letter.T, y_letter_encoded)\n",
    "\n",
    "tqda.predict(X_letter.T[:, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634477c4",
   "metadata": {},
   "source": [
    "### FasterQDA\n",
    "\n",
    "Definir una clase FasterQDA que herede de TensorizedQDA y redefina predict para predecir todas las observaciones juntas, sin el for sobre filas de X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b21da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FasterQDA(TensorizedQDA):\n",
    "    \"\"\"\n",
    "    Versión vectorizada (sin bucles en predict), \n",
    "    con matriz intermedia ineficiente (matriz N x N).\n",
    "    \"\"\"\n",
    "\n",
    "    def _predict_log_conditionals_batch(self, X):\n",
    "        # Dimensiones iniciales\n",
    "        k, p, _ = self.tensor_means.shape # self.tensor_means: (k, p, 1)    → k clases, p features\n",
    "        n = X.shape[1]                    # X: (p, n)                       → p features, n observaciones\n",
    "\n",
    "        # Cálculo resta: D = X - medias\n",
    "        D = X[None, :, :] - self.tensor_means   # X: (1, p, n) - Medias: (k, p, 1) → D: (k, p, n)\n",
    "\n",
    "        # Cálculo de la distancia cuadrática \n",
    "        quad_terms = np.empty((k, n)) # Almacena distancias por cada k clase y observación n\n",
    "\n",
    "        for j in range(k):\n",
    "            D_j = D[j]                          # Shape: (p, n)\n",
    "            inv_cov_j = self.tensor_inv_cov[j]  # Shape: (p, p)\n",
    "\n",
    "            # ---------------------------------------------------------\n",
    "            # Generación de matriz n x n\n",
    "            # ---------------------------------------------------------\n",
    "            # Al multiplicar D_j.T (n, p) @ inv (p, p) @ D_j (p, n), el resultado final es una matriz de (n, n)\n",
    "            # solo nos importa cada dato consigo mismo (la diagonal)\n",
    "            \n",
    "            Q_j = D_j.T @ inv_cov_j @ D_j      # matriz (n, n)\n",
    "\n",
    "            # Nos quedamos con la diagonal \n",
    "            quad_terms[j, :] = np.diag(Q_j)    \n",
    "            # ---------------------------------------------------------\n",
    "\n",
    "        \n",
    "        # log_det es (k,). Lo convertimos a (k, 1) para operar con quad_terms\n",
    "        log_det = np.log(LA.det(self.tensor_inv_cov))[:, None]\n",
    "        \n",
    "        # Fórmula final: 0.5 * log_det - 0.5 * distancia\n",
    "        return 0.5 * log_det - 0.5 * quad_terms\n",
    "\n",
    "    def predict(self, X):\n",
    "        # traigo el log-condicionales \n",
    "        log_cond = self._predict_log_conditionals_batch(X)\n",
    "\n",
    "        # Sumamos el log_a_priori \n",
    "        log_post = self.log_a_priori[:, None] + log_cond\n",
    "\n",
    "        # Elegimos la clase ganadora → por columna\n",
    "        y_hat = np.argmax(log_post, axis=0)\n",
    "\n",
    "        return y_hat.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e082abd",
   "metadata": {},
   "source": [
    "5. Demostrar que\n",
    "$$\n",
    "diag(A \\cdot B) = \\sum_{cols} A \\odot B^T = np.sum(A \\odot B^T, axis=1)\n",
    "$$\n",
    "es decir, que se puede \"esquivar\" la matriz de $n \\times n$ usando matrices de $n \\times p$. También se puede usar, de forma equivalente,\n",
    "$$\n",
    "np.sum(A^T \\odot B, axis=0).T\n",
    "$$\n",
    "queda a preferencia del alumno cuál usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "262b9198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagonal original:\n",
      " [-1.66909089  1.8681791  -0.8452777   1.94627243 -0.7281601 ]\n",
      "Suma optimizada:\n",
      " [-1.66909089  1.8681791  -0.8452777   1.94627243 -0.7281601 ]\n",
      "¿Son iguales? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Se definen dimensiones arbitrarias\n",
    "n = 5\n",
    "k = 7\n",
    "\n",
    "# Se crean matrices aleatorias, con esas dimensiones\n",
    "A = np.random.randn(n, k)\n",
    "B = np.random.randn(k, n)\n",
    "\n",
    "# Forma costosa, con producto matricial completo y extrayendo diagonal\n",
    "producto_matricial = A @ B  # Dimensión (n, n)\n",
    "diagonal_original = np.diag(producto_matricial)\n",
    "\n",
    "# Forma optimizada, con las sumas del producto elemento a elemento\n",
    "# Se transpone B: (k, n) -> (n, k), para que coincida con A\n",
    "optimizada = np.sum(A * B.T, axis=1)\n",
    "\n",
    "# Verificación, con allclose por si hay errores de redondeo\n",
    "son_iguales = np.allclose(diagonal_original, optimizada)\n",
    "\n",
    "print(\"Diagonal original:\\n\", diagonal_original)\n",
    "print(\"Suma optimizada:\\n\", optimizada)\n",
    "print(\"¿Son iguales?\", son_iguales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553097f6",
   "metadata": {},
   "source": [
    "## Comparar modelos con benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfa2cf8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ff0a565b944d17bdc15e73019c0d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA (MEM):   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2183e62a98043c0a3d6ba0a1039479e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA (TIME):   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63236acf1c404d11b9e659fc764f222e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TensorizedQDA (MEM):   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7eedb0258f428ea0504c626afe8b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TensorizedQDA (TIME):   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1384c1aeb44f348a936efb8582e8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FasterQDA (MEM):   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ba8f3c5f75b46b8946f16208704fff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FasterQDA (TIME):   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QDA \n",
    "b.bench(QDA)\n",
    "\n",
    "# TensorizedQDA\n",
    "b.bench(TensorizedQDA)\n",
    "\n",
    "# FasterQDA\n",
    "b.bench(FasterQDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "119f3fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_median_ms</th>\n",
       "      <th>train_std_ms</th>\n",
       "      <th>test_median_ms</th>\n",
       "      <th>test_std_ms</th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>train_mem_median_mb</th>\n",
       "      <th>train_mem_std_mb</th>\n",
       "      <th>test_mem_median_mb</th>\n",
       "      <th>test_mem_std_mb</th>\n",
       "      <th>train_speedup</th>\n",
       "      <th>test_speedup</th>\n",
       "      <th>train_mem_reduction</th>\n",
       "      <th>test_mem_reduction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>8.44575</td>\n",
       "      <td>5.766681</td>\n",
       "      <td>2167.88590</td>\n",
       "      <td>563.283321</td>\n",
       "      <td>0.886117</td>\n",
       "      <td>0.270096</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.098974</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TensorizedQDA</th>\n",
       "      <td>10.33575</td>\n",
       "      <td>6.688959</td>\n",
       "      <td>456.66145</td>\n",
       "      <td>163.644657</td>\n",
       "      <td>0.885303</td>\n",
       "      <td>0.268463</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.154099</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.817140</td>\n",
       "      <td>4.747250</td>\n",
       "      <td>1.006082</td>\n",
       "      <td>0.642279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FasterQDA</th>\n",
       "      <td>15.06945</td>\n",
       "      <td>6.940555</td>\n",
       "      <td>1563.86805</td>\n",
       "      <td>167.668471</td>\n",
       "      <td>0.884827</td>\n",
       "      <td>0.268951</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>258.234673</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.560455</td>\n",
       "      <td>1.386233</td>\n",
       "      <td>1.004255</td>\n",
       "      <td>0.000383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train_median_ms  train_std_ms  test_median_ms  test_std_ms  \\\n",
       "model                                                                       \n",
       "QDA                    8.44575      5.766681      2167.88590   563.283321   \n",
       "TensorizedQDA         10.33575      6.688959       456.66145   163.644657   \n",
       "FasterQDA             15.06945      6.940555      1563.86805   167.668471   \n",
       "\n",
       "               mean_accuracy  train_mem_median_mb  train_mem_std_mb  \\\n",
       "model                                                                 \n",
       "QDA                 0.886117             0.270096          0.002008   \n",
       "TensorizedQDA       0.885303             0.268463          0.002148   \n",
       "FasterQDA           0.884827             0.268951          0.001919   \n",
       "\n",
       "               test_mem_median_mb  test_mem_std_mb  train_speedup  \\\n",
       "model                                                               \n",
       "QDA                      0.098974         0.000705       1.000000   \n",
       "TensorizedQDA            0.154099         0.000158       0.817140   \n",
       "FasterQDA              258.234673         0.000695       0.560455   \n",
       "\n",
       "               test_speedup  train_mem_reduction  test_mem_reduction  \n",
       "model                                                                 \n",
       "QDA                1.000000             1.000000            1.000000  \n",
       "TensorizedQDA      4.747250             1.006082            0.642279  \n",
       "FasterQDA          1.386233             1.004255            0.000383  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = b.summary(baseline=\"QDA\")\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de007667",
   "metadata": {},
   "source": [
    "Vemos que TensorizedQDA entrena en el mismo tiempo que el QDA base y clasifica con la misma accuracy, pero es mucho más rápido en predicción.\n",
    "FasterQDA no lo mejora porque empieza a comparar todas las observaciones contra todas y arma una matriz gigante N×N que consume 258 MB de RAM y ralentiza todo el proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa649e73",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a2c8795",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa4cbe4",
   "metadata": {},
   "source": [
    "## Cholesky\n",
    "\n",
    "Hasta ahora todos los esfuerzos fueron enfocados en realizar una predicción más rápida. Los tiempos de entrenamiento (teóricos al menos) siguen siendo los mismos o hasta (minúsculamente) peores, dado que todas las mejoras siguen llamando al método `_fit_params` original de `QDA`.\n",
    "\n",
    "La descomposición/factorización de [Cholesky](https://en.wikipedia.org/wiki/Cholesky_decomposition#Statement) permite factorizar una matriz definida positiva $A = LL^T$ donde $L$ es una matriz triangular inferior. En particular, si bien se asume que $p \\ll n$, invertir la matriz de covarianzas $\\Sigma$ para cada clase impone un cuello de botella que podría alivianarse. Teniendo en cuenta que las matrices de covarianza son simétricas y salvo degeneración, definidas positivas, Cholesky como mínimo debería permitir invertir la matriz más rápido.\n",
    "\n",
    "*Nota: observar que calcular* $A^{-1}b$ *equivale a resolver el sistema* $Ax=b$.\n",
    "\n",
    "### 3) Diferencias entre implementaciones de `QDA_Chol`\n",
    "\n",
    "8. Si una matriz $A$ tiene fact. de Cholesky $A=LL^T$, expresar $A^{-1}$ en términos de $L$. ¿Cómo podría esto ser útil en la forma cuadrática de QDA?\n",
    "\n",
    "Al aplicar la factorización de Cholesky a la matriz de convarianzas (matriz simétrica y definida positiva siempre que no hayan features perfectaemente colineales) se puede representar como $\\Sigma = $LL^T$, de tal manera que la expresión $(x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j)$ se puede reescribir como:\n",
    "\n",
    "$$\n",
    "(x-\\mu_j)^T (L_j L_j^T)^{-1} (x- \\mu_j)\n",
    "$$\n",
    "y operando un poco:\n",
    "$$\n",
    "(x-\\mu_j)^T (L_j^{-1})^T L_j^{-1} (x- \\mu_j)\n",
    "$$\n",
    "$$\n",
    "[L_j^{-1} (x- \\mu_j)]^T [L_j^{-1} (x- \\mu_j)]\n",
    "$$\n",
    "Si representamos $L_j^{-1} (x- \\mu_j)$ como $y$, la expresión puede verse como\n",
    "$$\n",
    "y^Ty = ||y||^2\n",
    "$$\n",
    "donde $y$ puede calcularse resolviendo un sistema de ecuaciones lineales triangular, que es relativamente sencillo con sustitución hacia adelante:\n",
    "$$\n",
    "L_j y = x- \\mu_j\n",
    "$$\n",
    "Por otro lado, respecto al logaritmo del determinante la matriz de covarianzas, se puede operar de la siguiente manera:\n",
    "$$\n",
    "\\log |\\Sigma_j| = \\log |L_j L_j^T| = \\log |L_j| + \\log |L_j^T| = 2 \\log |L_j|\n",
    "$$\n",
    "donde $|L_j|$, al ser $L_j$ una matriz triangular inferior, es el producto de sus elementos en la diagonal.\n",
    "\n",
    "Finalmente, la forma cuadrática de QDA se puede reescribir como:\n",
    "$$\n",
    "\\log{f_j(x)} = \\log{ \\left( \\prod_{i=1}^p l_{ii} \\right)} - \\frac{1}{2} \\|y\\|^2\n",
    "$$\n",
    "En resumen, aplicar Cholesky en QDA transforma un problema con  inversión de matrices en un problema de resolución de sistemas de ecuaciones lineales triangulares.\n",
    "\n",
    "\n",
    "7. Explicar las diferencias entre `QDA_Chol1`y `QDA` y cómo `QDA_Chol1` llega, paso a paso, hasta las predicciones.\n",
    "\n",
    "`QDA` en su método `_fit_params` calcula e invierte la matriz de covarianzas para cada clase y las almacena en `self.inv_covs`.\n",
    "\n",
    "`QDA_Chol1`, en el mismo método, calcula la matriz de covarianzas y le aplica la factorización de Cholesky, obteniendo la matriz $L$. Luego, calcula la inversa de $L$ y la almacena en `self.L_invs`. Esto es para cada clase.\n",
    "\n",
    "A la hora de realizar una predición, en el método `_predict_log_conditional`, en `QDA` prácticamente utiliza la formulación provista inicialmente para el cálculo de la log-verosimilitud, con algunos cambios.\n",
    "$$\n",
    "\\log{f_j(x)} = \\frac{1}{2}\\log |\\Sigma_j^{-1}| - \\frac{1}{2} (x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j)\n",
    "$$\n",
    ", mientras que `QDA_Chol1` aprovecha, por un lado, la propiedad de que el determinante de $L^{-1}$ es el producto de los elementos de su diagonal y, por otro, la equivalencia $$(x-\\mu_j)^T \\Sigma_j^{-1} (x- \\mu_j) = \\|y\\|^2$$, tal que el cálculo de la log-verosimilitud resulta:\n",
    "$$\n",
    "\\log{f_j(x)} = -\\log{ \\left( \\prod_{i=1}^p l_{ii} \\right)} - \\frac{1}{2} \\|y\\|^2\n",
    "$$\n",
    "llegando ambos al mismo resultado porque todos los reemplazos corresponden a equivalencias matemáticas, sin utilizar aproximaciones.\n",
    "\n",
    "8. ¿Cuáles son las diferencias entre `QDA_Chol1`, `QDA_Chol2` y `QDA_Chol3`?\n",
    "\n",
    "`QDA_Chol1` y `QDA_Chol2` se diferencian en que la primera calcula la inversa de $L$ y luego, para predecir, utiliza el producto de esta matriz con $x$ insesgado para calcular $y$, mientras que la segunda se queda directamente con $L$ y, para predecir, resuelve el SEL triangular para obtener $y$.\n",
    "\n",
    "`QDA_Chol3` es similar a `QDA_Chol1`, pero utiliza otra función para calcular $L^{-1}$: `QDA_Chol1` utiliza `numpy.inv()` y `QDA_Chol3` utiliza `scipy.linalg.lapack.dtrtri()`.\n",
    "\n",
    "9. Comparar la performance de las 7 variantes de QDA implementadas hasta ahora ¿Qué se observa?¿Hay alguna de las implementaciones de `QDA_Chol` que sea claramente mejor que las demás?¿Alguna que sea peor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84678165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa951ddabfb5431ea77409fe9a8efa2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol1 (MEM):   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71bca7563cb4b1abb5fd6409d876c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol1 (TIME):   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dc886db22541e6bc36ea6770642b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol2 (MEM):   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4b949d0e85421381fdf59bbaa6633e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol2 (TIME):   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbcd40618754463b3fd1f178a8e0345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol3 (MEM):   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4f1cac15f44d65b2cf8d5fc4d376ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QDA_Chol3 (TIME):   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Antes debe haberse ejecutado el bench de los otros modelos\n",
    "b.bench(QDA_Chol1)\n",
    "\n",
    "b.bench(QDA_Chol2)\n",
    "\n",
    "b.bench(QDA_Chol3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85463880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_median_ms</th>\n",
       "      <th>train_std_ms</th>\n",
       "      <th>test_median_ms</th>\n",
       "      <th>test_std_ms</th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>train_mem_median_mb</th>\n",
       "      <th>train_mem_std_mb</th>\n",
       "      <th>test_mem_median_mb</th>\n",
       "      <th>test_mem_std_mb</th>\n",
       "      <th>train_speedup</th>\n",
       "      <th>test_speedup</th>\n",
       "      <th>train_mem_reduction</th>\n",
       "      <th>test_mem_reduction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>8.44575</td>\n",
       "      <td>5.766681</td>\n",
       "      <td>2167.88590</td>\n",
       "      <td>563.283321</td>\n",
       "      <td>0.886117</td>\n",
       "      <td>0.270096</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.098974</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TensorizedQDA</th>\n",
       "      <td>10.33575</td>\n",
       "      <td>6.688959</td>\n",
       "      <td>456.66145</td>\n",
       "      <td>163.644657</td>\n",
       "      <td>0.885303</td>\n",
       "      <td>0.268463</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.154099</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.817140</td>\n",
       "      <td>4.747250</td>\n",
       "      <td>1.006082</td>\n",
       "      <td>0.642279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FasterQDA</th>\n",
       "      <td>15.06945</td>\n",
       "      <td>6.940555</td>\n",
       "      <td>1563.86805</td>\n",
       "      <td>167.668471</td>\n",
       "      <td>0.884827</td>\n",
       "      <td>0.268951</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>258.234673</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.560455</td>\n",
       "      <td>1.386233</td>\n",
       "      <td>1.004255</td>\n",
       "      <td>0.000383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol1</th>\n",
       "      <td>8.86170</td>\n",
       "      <td>3.912978</td>\n",
       "      <td>1118.86475</td>\n",
       "      <td>334.098266</td>\n",
       "      <td>0.884890</td>\n",
       "      <td>0.269661</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.095322</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.953062</td>\n",
       "      <td>1.937576</td>\n",
       "      <td>1.001613</td>\n",
       "      <td>1.038318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol2</th>\n",
       "      <td>8.08125</td>\n",
       "      <td>1.683816</td>\n",
       "      <td>2519.32020</td>\n",
       "      <td>227.968456</td>\n",
       "      <td>0.884770</td>\n",
       "      <td>0.268478</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.096025</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>1.045104</td>\n",
       "      <td>0.860504</td>\n",
       "      <td>1.006024</td>\n",
       "      <td>1.030708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol3</th>\n",
       "      <td>10.21700</td>\n",
       "      <td>6.963034</td>\n",
       "      <td>1196.03340</td>\n",
       "      <td>317.139291</td>\n",
       "      <td>0.885433</td>\n",
       "      <td>0.268906</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.095160</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.826637</td>\n",
       "      <td>1.812563</td>\n",
       "      <td>1.004426</td>\n",
       "      <td>1.040087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train_median_ms  train_std_ms  test_median_ms  test_std_ms  \\\n",
       "model                                                                       \n",
       "QDA                    8.44575      5.766681      2167.88590   563.283321   \n",
       "TensorizedQDA         10.33575      6.688959       456.66145   163.644657   \n",
       "FasterQDA             15.06945      6.940555      1563.86805   167.668471   \n",
       "QDA_Chol1              8.86170      3.912978      1118.86475   334.098266   \n",
       "QDA_Chol2              8.08125      1.683816      2519.32020   227.968456   \n",
       "QDA_Chol3             10.21700      6.963034      1196.03340   317.139291   \n",
       "\n",
       "               mean_accuracy  train_mem_median_mb  train_mem_std_mb  \\\n",
       "model                                                                 \n",
       "QDA                 0.886117             0.270096          0.002008   \n",
       "TensorizedQDA       0.885303             0.268463          0.002148   \n",
       "FasterQDA           0.884827             0.268951          0.001919   \n",
       "QDA_Chol1           0.884890             0.269661          0.002164   \n",
       "QDA_Chol2           0.884770             0.268478          0.002137   \n",
       "QDA_Chol3           0.885433             0.268906          0.001967   \n",
       "\n",
       "               test_mem_median_mb  test_mem_std_mb  train_speedup  \\\n",
       "model                                                               \n",
       "QDA                      0.098974         0.000705       1.000000   \n",
       "TensorizedQDA            0.154099         0.000158       0.817140   \n",
       "FasterQDA              258.234673         0.000695       0.560455   \n",
       "QDA_Chol1                0.095322         0.000500       0.953062   \n",
       "QDA_Chol2                0.096025         0.000260       1.045104   \n",
       "QDA_Chol3                0.095160         0.000407       0.826637   \n",
       "\n",
       "               test_speedup  train_mem_reduction  test_mem_reduction  \n",
       "model                                                                 \n",
       "QDA                1.000000             1.000000            1.000000  \n",
       "TensorizedQDA      4.747250             1.006082            0.642279  \n",
       "FasterQDA          1.386233             1.004255            0.000383  \n",
       "QDA_Chol1          1.937576             1.001613            1.038318  \n",
       "QDA_Chol2          0.860504             1.006024            1.030708  \n",
       "QDA_Chol3          1.812563             1.004426            1.040087  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = b.summary(baseline=\"QDA\")\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0216278d",
   "metadata": {},
   "source": [
    "`QDA_Chol1` parece ser la mejor de las implementaciones de Cholesky en cuanto a velocidad en train y test, superando al `QDA` base pero sin hacerlo respecto de `FasteQDA`. `QDA_Chol2` incluso resulta ser más lento para predecir y `QDA_Chol3` es bastante parecida a la primera.\n",
    "\n",
    "Respecto a memoria, los 3 modelos con Cholesky tienen una leve mejora pero no parece significativa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373ca153",
   "metadata": {},
   "source": [
    "### 4) Optimización\n",
    "\n",
    "12. Implementar el modelo `TensorizedChol` paralelizando sobre clases/observaciones según corresponda. Se recomienda heredarlo de alguna de las implementaciones de `QDA_Chol`, aunque la elección de cuál de ellas queda a cargo del alumno según lo observado en los benchmarks de puntos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60ac268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorizedChol(QDA_Chol1):\n",
    "    def _fit_params(self, X, y):\n",
    "        super()._fit_params(X, y)\n",
    "\n",
    "        self.tensor_L_invs = np.stack(self.L_invs)\n",
    "        self.tensor_means = np.stack(self.means)\n",
    "\n",
    "    def _predict_log_conditionals(self, x):\n",
    "        unbiased_x = x - self.tensor_means\n",
    "        y = self.tensor_L_invs @ unbiased_x\n",
    "\n",
    "        return np.log(self.tensor_L_invs.diagonal(axis1=1, axis2=2).prod(axis=1)) - 0.5 * (y**2).sum(axis=1).flatten()\n",
    "\n",
    "    def _predict_one(self, x):\n",
    "        return np.argmax(self.log_a_priori + self._predict_log_conditionals(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a14f70",
   "metadata": {},
   "source": [
    "13. Implementar el modelo `EfficientChol` combinando los insights de `EfficientQDA` y `TensorizedChol`. Si se desea, se puede implementar `FasterChol` como ayuda, pero no se contempla para el punto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45ffad1",
   "metadata": {},
   "source": [
    "14. Comparar la performance de las 9 variantes de QDA implementadas ¿Qué se observa? A modo de opinión ¿Se condice con lo esperado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19955d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40c81ef06bd44c3a0af7c31599a91c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TensorizedChol (MEM):   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03d5cf8af764e128ff112f85590f259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TensorizedChol (TIME):   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b.bench(TensorizedChol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb2fadec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_median_ms</th>\n",
       "      <th>train_std_ms</th>\n",
       "      <th>test_median_ms</th>\n",
       "      <th>test_std_ms</th>\n",
       "      <th>mean_accuracy</th>\n",
       "      <th>train_mem_median_mb</th>\n",
       "      <th>train_mem_std_mb</th>\n",
       "      <th>test_mem_median_mb</th>\n",
       "      <th>test_mem_std_mb</th>\n",
       "      <th>train_speedup</th>\n",
       "      <th>test_speedup</th>\n",
       "      <th>train_mem_reduction</th>\n",
       "      <th>test_mem_reduction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>8.44575</td>\n",
       "      <td>5.766681</td>\n",
       "      <td>2167.88590</td>\n",
       "      <td>563.283321</td>\n",
       "      <td>0.886117</td>\n",
       "      <td>0.270096</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.098974</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TensorizedQDA</th>\n",
       "      <td>10.33575</td>\n",
       "      <td>6.688959</td>\n",
       "      <td>456.66145</td>\n",
       "      <td>163.644657</td>\n",
       "      <td>0.885303</td>\n",
       "      <td>0.268463</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.154099</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.817140</td>\n",
       "      <td>4.747250</td>\n",
       "      <td>1.006082</td>\n",
       "      <td>0.642279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FasterQDA</th>\n",
       "      <td>15.06945</td>\n",
       "      <td>6.940555</td>\n",
       "      <td>1563.86805</td>\n",
       "      <td>167.668471</td>\n",
       "      <td>0.884827</td>\n",
       "      <td>0.268951</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>258.234673</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.560455</td>\n",
       "      <td>1.386233</td>\n",
       "      <td>1.004255</td>\n",
       "      <td>0.000383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol1</th>\n",
       "      <td>8.86170</td>\n",
       "      <td>3.912978</td>\n",
       "      <td>1118.86475</td>\n",
       "      <td>334.098266</td>\n",
       "      <td>0.884890</td>\n",
       "      <td>0.269661</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.095322</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.953062</td>\n",
       "      <td>1.937576</td>\n",
       "      <td>1.001613</td>\n",
       "      <td>1.038318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol2</th>\n",
       "      <td>8.08125</td>\n",
       "      <td>1.683816</td>\n",
       "      <td>2519.32020</td>\n",
       "      <td>227.968456</td>\n",
       "      <td>0.884770</td>\n",
       "      <td>0.268478</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.096025</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>1.045104</td>\n",
       "      <td>0.860504</td>\n",
       "      <td>1.006024</td>\n",
       "      <td>1.030708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA_Chol3</th>\n",
       "      <td>10.21700</td>\n",
       "      <td>6.963034</td>\n",
       "      <td>1196.03340</td>\n",
       "      <td>317.139291</td>\n",
       "      <td>0.885433</td>\n",
       "      <td>0.268906</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.095160</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.826637</td>\n",
       "      <td>1.812563</td>\n",
       "      <td>1.004426</td>\n",
       "      <td>1.040087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TensorizedChol</th>\n",
       "      <td>8.37340</td>\n",
       "      <td>2.258211</td>\n",
       "      <td>83.40165</td>\n",
       "      <td>15.772709</td>\n",
       "      <td>0.885755</td>\n",
       "      <td>0.269119</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.157921</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>1.008640</td>\n",
       "      <td>25.993321</td>\n",
       "      <td>1.003629</td>\n",
       "      <td>0.626733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                train_median_ms  train_std_ms  test_median_ms  test_std_ms  \\\n",
       "model                                                                        \n",
       "QDA                     8.44575      5.766681      2167.88590   563.283321   \n",
       "TensorizedQDA          10.33575      6.688959       456.66145   163.644657   \n",
       "FasterQDA              15.06945      6.940555      1563.86805   167.668471   \n",
       "QDA_Chol1               8.86170      3.912978      1118.86475   334.098266   \n",
       "QDA_Chol2               8.08125      1.683816      2519.32020   227.968456   \n",
       "QDA_Chol3              10.21700      6.963034      1196.03340   317.139291   \n",
       "TensorizedChol          8.37340      2.258211        83.40165    15.772709   \n",
       "\n",
       "                mean_accuracy  train_mem_median_mb  train_mem_std_mb  \\\n",
       "model                                                                  \n",
       "QDA                  0.886117             0.270096          0.002008   \n",
       "TensorizedQDA        0.885303             0.268463          0.002148   \n",
       "FasterQDA            0.884827             0.268951          0.001919   \n",
       "QDA_Chol1            0.884890             0.269661          0.002164   \n",
       "QDA_Chol2            0.884770             0.268478          0.002137   \n",
       "QDA_Chol3            0.885433             0.268906          0.001967   \n",
       "TensorizedChol       0.885755             0.269119          0.001976   \n",
       "\n",
       "                test_mem_median_mb  test_mem_std_mb  train_speedup  \\\n",
       "model                                                                \n",
       "QDA                       0.098974         0.000705       1.000000   \n",
       "TensorizedQDA             0.154099         0.000158       0.817140   \n",
       "FasterQDA               258.234673         0.000695       0.560455   \n",
       "QDA_Chol1                 0.095322         0.000500       0.953062   \n",
       "QDA_Chol2                 0.096025         0.000260       1.045104   \n",
       "QDA_Chol3                 0.095160         0.000407       0.826637   \n",
       "TensorizedChol            0.157921         0.000249       1.008640   \n",
       "\n",
       "                test_speedup  train_mem_reduction  test_mem_reduction  \n",
       "model                                                                  \n",
       "QDA                 1.000000             1.000000            1.000000  \n",
       "TensorizedQDA       4.747250             1.006082            0.642279  \n",
       "FasterQDA           1.386233             1.004255            0.000383  \n",
       "QDA_Chol1           1.937576             1.001613            1.038318  \n",
       "QDA_Chol2           0.860504             1.006024            1.030708  \n",
       "QDA_Chol3           1.812563             1.004426            1.040087  \n",
       "TensorizedChol     25.993321             1.003629            0.626733  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary = b.summary(baseline=\"QDA\")\n",
    "df_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
